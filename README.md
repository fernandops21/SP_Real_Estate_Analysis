# üèôÔ∏è S√£o Paulo Real Estate ‚Äî An√°lise e Modelagem Preditiva  
**Projeto did√°tico de Machine Learning para previs√£o de pre√ßos de aluguel em S√£o Paulo.**

---

## üìå Descri√ß√£o

Este projeto tem como objetivo ensinar, de maneira pr√°tica, os fundamentos de Machine Learning aplicados a dados reais do mercado imobili√°rio de S√£o Paulo.  
A partir de um dataset p√∫blico do Kaggle, realizamos:

- An√°lise explorat√≥ria (EDA)  
- Visualiza√ß√£o geogr√°fica  
- Tratamento de dados  
- Cria√ß√£o de features  
- Treino/teste  
- Avalia√ß√£o por RMSE  
- Cross-Validation  
- Grid Search para otimiza√ß√£o  

√â um projeto introdut√≥rio, ideal como material de aula para ML supervisionado.

---

## üóÇÔ∏è Etapas do Projeto

### **1. Download Autom√°tico (KaggleHub)**
Os dados s√£o baixados automaticamente via `kagglehub`:

- sem necessidade de baixar manualmente
- dataset sempre atualizado
- integra√ß√£o simples com notebooks

---

### **2. An√°lise Explorat√≥ria**
Inclui:

- `df.head()`, `df.info()`
- histogramas
- estat√≠sticas descritivas
- an√°lise de correla√ß√£o
- distribui√ß√£o por distrito e tipo de im√≥vel

---

### **3. Visualiza√ß√£o Geogr√°fica**
Criamos um mapa interativo com Plotly, mostrando:

- latitude e longitude  
- pre√ßo do aluguel  
- tamanho do im√≥vel  
- dispers√£o por regi√µes da cidade  

Esse passo ajuda a compreender padr√µes espaciais do mercado.

---

### **4. Limpeza e Prepara√ß√£o**
Processos aplicados:

- remo√ß√£o de colunas constantes ou irrelevantes  
- filtragem apenas para im√≥veis de **aluguel**  
- tratamento de valores faltantes  
- transforma√ß√£o da vari√°vel `District` via **One-Hot Encoding**  
- separa√ß√£o entre features (X) e target (Y)

---

### **5. Split Treino/Teste**
Utilizamos `train_test_split` para garantir avalia√ß√£o imparcial.

---

### **6. Modelagem**
Modelos testados:

- **Regress√£o Linear** (baseline, simples, explicativo)  
- **Decision Tree Regressor** (flex√≠vel, por√©m sujeito a overfitting)  
- **Random Forest Regressor** (melhor desempenho geral)

Os modelos foram avaliados usando:

- **Erro Quadr√°tico M√©dio (MSE)**
- **Raiz do Erro Quadr√°tico M√©dio (RMSE)**

Demonstrando:

- Linear ‚Üí underfitting  
- √Årvore ‚Üí overfitting  
- Random Forest ‚Üí melhor equil√≠brio  

---

### **7. Valida√ß√£o Cruzada**
Aplicamos Cross-Validation (10 folds) para obter m√©tricas mais robustas e evitar conclus√µes baseadas em um √∫nico split.

---

### **8. Hyperparameter Tuning**
Usamos `GridSearchCV` para testar combina√ß√µes de hiperpar√¢metros do Random Forest:

- n√∫mero de √°rvores (`n_estimators`)  
- n√∫mero de features (`max_features`)  
- uso ou n√£o de bootstrap  

O melhor modelo (`best_estimator_`) √© usado para prever no conjunto de teste.

---

### **9. Avalia√ß√£o Final**
Com o melhor modelo:

- c√°lculo do RMSE final  
- gr√°fico comparando valores reais vs previstos  
- an√°lise do desempenho do modelo

---

## üìä Tecnologias Utilizadas

- Python 3  
- Pandas  
- NumPy  
- Seaborn  
- Matplotlib  
- Plotly  
- Scikit-Learn  
- KaggleHub  

---